{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offline Multiplayer Eval\n",
    "In this minimal tutorial, we will showcase how you can evaluate your models offline against a fixed opponent. In this case, we will pick a basket of two- and multi-player environments, run the model for a fixed number of total games, and finally show the win/loss/draw rates for each environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Defining parameters and loading the model\n",
    "First we need to specifiy the environment(s), number of games and opponent model name (we recommend using OpenRouter to run the opponent model).\n",
    "\n",
    "For the purpose of this guide, we will evaluate a quantized qwen3 8b model (`Qwen/Qwen3-8B-GGUF`) against gemini 2.0 lite flash (`google/gemini-2.0-flash-001`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from transformers) (2.2.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: bitsandbytes in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (0.45.5)\n",
      "Requirement already satisfied: torch<3,>=2.0 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from bitsandbytes) (2.7.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from bitsandbytes) (2.2.4)\n",
      "Requirement already satisfied: filelock in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from torch<3,>=2.0->bitsandbytes) (4.13.0)\n",
      "Requirement already satisfied: setuptools in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from torch<3,>=2.0->bitsandbytes) (75.8.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from torch<3,>=2.0->bitsandbytes) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from torch<3,>=2.0->bitsandbytes) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from torch<3,>=2.0->bitsandbytes) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from torch<3,>=2.0->bitsandbytes) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from torch<3,>=2.0->bitsandbytes) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from torch<3,>=2.0->bitsandbytes) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from torch<3,>=2.0->bitsandbytes) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from torch<3,>=2.0->bitsandbytes) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from torch<3,>=2.0->bitsandbytes) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from torch<3,>=2.0->bitsandbytes) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from torch<3,>=2.0->bitsandbytes) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from torch<3,>=2.0->bitsandbytes) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from torch<3,>=2.0->bitsandbytes) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from torch<3,>=2.0->bitsandbytes) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from torch<3,>=2.0->bitsandbytes) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from torch<3,>=2.0->bitsandbytes) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from torch<3,>=2.0->bitsandbytes) (3.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from sympy>=1.13.3->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers \n",
    "!pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "/home/guertlerlo/miniforge3/envs/torch/lib/python3.12/site-packages/torch/cuda/__init__.py:789: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os, csv, dotenv\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import textarena as ta \n",
    "\n",
    "# defining parameters\n",
    "NUM_EPISODES = 8\n",
    "EVAL_ENV_IDS = [(\"TicTacToe-v0\", 2), (\"DontSayIt-v0\", 2)] #, (\"Snake-v0\", 4)]\n",
    "OPPONENT_NAME = \"google/gemini-2.0-flash-001\"\n",
    "MODEL_NAME = \"Qwen/Qwen3-0.6B\"\n",
    "\n",
    "# load the OpenRouter api key \n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# loading the models\n",
    "model = ta.agents.HFLocalAgent(\n",
    "    model_name=MODEL_NAME,\n",
    "    quantize=True,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "opponent = ta.agents.OpenRouterAgent(\n",
    "    model_name=OPPONENT_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Defining the Game Loop\n",
    "Now we can define the actual game loop. It should take both models as input, randomly allocate roles, initialize the environment, play the game, and return the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_game_loop(env_id, num_players, model, opponent):\n",
    "    # build the environment\n",
    "    env = ta.make(env_id) # already wrapped with the default wrappers\n",
    "    # reset the environment\n",
    "    env.reset(num_players=num_players)\n",
    "\n",
    "    # randomly allocate the player id to the model to be evaluated\n",
    "    model_player_id = np.random.randint(0, num_players)\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        pid, observation = env.get_observation()\n",
    "        # get action\n",
    "        if pid==model_player_id:\n",
    "            action = model(observation)\n",
    "        else:\n",
    "            action = opponent(observation)\n",
    "\n",
    "        # step in the env\n",
    "        done, info = env.step(action=action)\n",
    "\n",
    "    # get final rewards\n",
    "    rewards = env.close()\n",
    "\n",
    "    # for simplicity we will average the opponent rewards (i.e. treating FFA multiplayer games as a two-player game)\n",
    "    return {\n",
    "        \"model_reward\": rewards[model_player_id],\n",
    "        \"opponent_reward\": np.mean(rewards[i] for i in range(num_players) if i != model_player_id)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Putting it all Together\n",
    "Finally, we can write our main loop that will iterate over all envs for the specified number of games and track the outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Environments:   0%|          | 0/2 [02:01<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize tracking variables\n",
    "results = defaultdict(list)\n",
    "\n",
    "# Prepare tqdm \n",
    "outer_bar = tqdm(EVAL_ENV_IDS, desc=\"Environments\")\n",
    "for (env_id, num_players) in outer_bar:\n",
    "    inner_bar = tqdm(range(NUM_EPISODES), desc=f\"Evaluating {env_id}\", leave=False)\n",
    "    env_results = {\n",
    "        \"wins\": 0, \"losses\": 0, \"draws\": 0,\n",
    "        \"total_reward_model\": 0.0, \"total_reward_opponent\": 0.0,\n",
    "        \"total_length\": 0,\n",
    "    }\n",
    "    for _ in inner_bar:\n",
    "        outcome = run_game_loop(env_id=env_id, num_players=num_players, model=model, opponent=opponent)\n",
    "        model_reward = outcome[\"model_reward\"]\n",
    "        opponent_reward = outcome[\"opponent_reward\"]\n",
    "\n",
    "        # Determine outcome\n",
    "        if model_reward > opponent_reward: env_results[\"wins\"] += 1\n",
    "        elif model_reward < opponent_reward: env_results[\"losses\"] += 1\n",
    "        else: env_results[\"draws\"] += 1\n",
    "\n",
    "        env_results[\"total_reward_model\"] += model_reward\n",
    "        env_results[\"total_reward_opponent\"] += opponent_reward\n",
    "        env_results[\"total_length\"] += 1\n",
    "\n",
    "        avg_reward_model = env_results[\"total_reward_model\"] / env_results[\"total_length\"]\n",
    "        avg_reward_opponent = env_results[\"total_reward_opponent\"] / env_results[\"total_length\"]\n",
    "\n",
    "        inner_bar.set_postfix({\n",
    "            \"Win%\": f\"{env_results['wins'] / env_results['total_length']:.2%}\",\n",
    "            \"Loss%\": f\"{env_results['losses'] / env_results['total_length']:.2%}\",\n",
    "            \"Draw%\": f\"{env_results['draws'] / env_results['total_length']:.2%}\",\n",
    "            \"Model R\": f\"{avg_reward_model:.2f}\",\n",
    "            \"Opp R\": f\"{avg_reward_opponent:.2f}\"\n",
    "        })\n",
    "\n",
    "    # Save results for this environment\n",
    "    results[\"env_id\"].append(env_id)\n",
    "    results[\"win_rate\"].append(env_results[\"wins\"] / NUM_EPISODES)\n",
    "    results[\"loss_rate\"].append(env_results[\"losses\"] / NUM_EPISODES)\n",
    "    results[\"draw_rate\"].append(env_results[\"draws\"] / NUM_EPISODES)\n",
    "    results[\"avg_model_reward\"].append(env_results[\"total_reward_model\"] / NUM_EPISODES)\n",
    "    results[\"avg_opponent_reward\"].append(env_results[\"total_reward_opponent\"] / NUM_EPISODES)\n",
    "    results[\"avg_game_length\"].append(env_results[\"total_length\"] / NUM_EPISODES)\n",
    "\n",
    "\n",
    "\n",
    "# Output results as a pretty table\n",
    "df = pd.DataFrame(results)\n",
    "from IPython.display import display\n",
    "display(df)\n",
    "\n",
    "# Save to CSV\n",
    "os.makedirs(\"eval_results\", exist_ok=True)\n",
    "df.to_csv(\"eval_results/eval_summary.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
